{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jkrue242/PortfolioOptimization/blob/main/portfolio_optimiztion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeAaPDe5DG7Q"
      },
      "source": [
        "### Portfolio Optimization using Deep Learning\n",
        "\n",
        "#### Implementation and modification of [this paper](https://arxiv.org/pdf/2005.13665).\n",
        "\n",
        "#### Modifications will include:\n",
        "1. Use of different recursive networks (Transformer, GRU, LSTM)\n",
        "2. Hyperparameter optimization\n",
        "3. Additional input features\n",
        "4. Loss function comparison between Sharpe and Sortino"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4iAhE-DG7R"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "J1u4aZ1nDG7R"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'PortfolioDataset' from 'data_utils' (/Users/josephkrueger/college/2025_spring/deep_learning/PortfolioOptimization/data_utils.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdata_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PortfolioDataset\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PortfolioTransformer\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msharpe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SharpeLoss\n",
            "\u001b[31mImportError\u001b[39m: cannot import name 'PortfolioDataset' from 'data_utils' (/Users/josephkrueger/college/2025_spring/deep_learning/PortfolioOptimization/data_utils.py)"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import warnings\n",
        "from data_utils import PortfolioDataset\n",
        "from transformer import PortfolioTransformer\n",
        "from sharpe import SharpeLoss\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hiut51PDG7S"
      },
      "source": [
        "In our analysis, we will build a simple portfolio of 4 indices:\n",
        "1. AGG (Agg. Bond ETF)\n",
        "2. DBC (Commodity Index)\n",
        "3. VTI (Vanguard Total Stock Index)\n",
        "4. VIX (CBOE Volatility Index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnIIQ_sFF3pR",
        "outputId": "f1c02c4f-2f9b-4461-bf88-d2b873dc8eca"
      },
      "outputs": [],
      "source": [
        "# constants for dataset and training stuff\n",
        "ETFS = [\"VOO\",\"QQQ\",\"GLD\"]\n",
        "N_TICKERS = len(ETFS)\n",
        "\n",
        "SAMPLE_DAYS = 50\n",
        "ROLLING_AVGS = [10, 30, 50]\n",
        "BATCH_SIZE = 64\n",
        "START_DATE = '2010-01-01'\n",
        "END_DATE ='2025-01-01'\n",
        "\n",
        "# try to use cuda for training\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Running notebook on {DEVICE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb5Ml3vGHLSt"
      },
      "source": [
        "Pull data from yfinance. Features used:\n",
        "1. Close Price\n",
        "2. Returns (% change of close)\n",
        "3. 10-day, 30-day, 50-day Rolling Averages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-si7ip5HBeD",
        "outputId": "45d22310-f4fe-4f00-fb72-d13e25d9b723"
      },
      "outputs": [],
      "source": [
        "ticker_df = yf.download(ETFS, start=START_DATE, end=END_DATE, group_by='ticker', auto_adjust=True)\n",
        "features = []\n",
        "for e in ETFS:\n",
        "  data = ticker_df[e].copy()\n",
        "\n",
        "  # returns features\n",
        "  data['return'] = data['Close'].pct_change().fillna(0)\n",
        "  data['cumulative_return'] = (1 + data['return']).cumprod() - 1\n",
        "\n",
        "  # rolling average feature\n",
        "  for i in ROLLING_AVGS:\n",
        "    data[f\"ma_{i}\"] = data['Close'].rolling(i).mean().fillna(method='bfill')\n",
        "\n",
        "  # build up feature list\n",
        "  features.append(data[['return'] + ['cumulative_return'] + [f\"ma_{i}\" for i in ROLLING_AVGS]])\n",
        "\n",
        "data = pd.concat(features, axis=1, keys=ETFS).dropna()\n",
        "N_FEATURES = len(data.columns)//N_TICKERS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eBeg-_eLDP-",
        "outputId": "e5e8a7dc-1aea-48de-e086-8c05694015cc"
      },
      "outputs": [],
      "source": [
        "print(f\"Number of features: {N_FEATURES}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "mJkyy8V8I9HX",
        "outputId": "7006f3c9-75e2-4836-c718-aaeee99fd5f5"
      },
      "outputs": [],
      "source": [
        "data.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sC5GqDnVDG7S"
      },
      "source": [
        "Plot all the features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UOFoBaYCDG7T",
        "outputId": "4d5c8238-158a-4e4e-c118-0d68ca71203f"
      },
      "outputs": [],
      "source": [
        "feature_names = data.columns.get_level_values(1).unique()\n",
        "\n",
        "for feature_name in feature_names:\n",
        "  # feature cross sections\n",
        "  feature_data = data.xs(feature_name, level=1, axis=1)\n",
        "\n",
        "  plt.figure(figsize=(14, 7))\n",
        "  ax = plt.gca()\n",
        "\n",
        "  feature_data.plot(ax=ax)\n",
        "\n",
        "  plt.title(f'{feature_name} Over Time for All ETFs')\n",
        "  plt.xlabel('Date')\n",
        "  plt.ylabel(feature_name.replace('_', ' ').title())\n",
        "\n",
        "  plt.legend(title='ETFs')\n",
        "\n",
        "  plt.grid(True)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5tNi27-THHr"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dxtKe7xJ7Ar",
        "outputId": "b8ba2e0c-deb9-4ee0-9f8e-f43b1200b8c7"
      },
      "outputs": [],
      "source": [
        "# load data\n",
        "dataset = PortfolioDataset(data, SAMPLE_DAYS)\n",
        "data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# build model\n",
        "model = PortfolioTransformer(\n",
        "  seq_len=SAMPLE_DAYS,\n",
        "  num_features=len(ETFS)*N_FEATURES,\n",
        "  num_assets=len(ETFS),\n",
        "  d_model=64,\n",
        "  nhead=4,\n",
        "  num_layers=2,\n",
        "  dim_ff=128,\n",
        "  dropout=0.1\n",
        ").to(DEVICE)\n",
        "\n",
        "# use neg sharpe as loss\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "loss_fn = SharpeLoss()\n",
        "\n",
        "for epoch in range(1, 200):\n",
        "  model.train()\n",
        "  total = 0\n",
        "\n",
        "  # batch train\n",
        "  for batch_idx, batch in enumerate(data_loader):\n",
        "    X = batch['features'].to(DEVICE)\n",
        "    R = batch['returns'].to(DEVICE)\n",
        "\n",
        "    # zero out\n",
        "    opt.zero_grad()\n",
        "\n",
        "    # forward pass to predict weights\n",
        "    w = model(X)\n",
        "\n",
        "    # printing loss\n",
        "    if batch_idx == 0:\n",
        "      print(f\"  Epoch {epoch:02d}, Batch {batch_idx:03d} - Predicted Weights (first sample):\")\n",
        "      weights_to_print = w[0].detach().cpu().numpy()\n",
        "      for i, etf in enumerate(ETFS):\n",
        "        print(f\"    {etf}: {weights_to_print[i]:.4f}\", end=\" \")\n",
        "      print()\n",
        "\n",
        "    # backprop\n",
        "    loss = loss_fn(w, R)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    total += loss.item()\n",
        "\n",
        "  l = total / len(data_loader)\n",
        "  print(f\"Epoch {epoch:02d}, Loss: {l:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6hArhqpoB1A"
      },
      "source": [
        "Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KlONwk4LckIh",
        "outputId": "4eb5f4a0-5b9d-41ca-ba8e-b2a98be9aff8"
      },
      "outputs": [],
      "source": [
        "# eval mode\n",
        "model.eval()\n",
        "predicted_weights = []\n",
        "actual_returns = []\n",
        "portfolio_returns = []\n",
        "dates = []\n",
        "all_dates = data.index[(SAMPLE_DAYS + 1):]\n",
        "\n",
        "# zero grad for prediciton\n",
        "with torch.no_grad():\n",
        "  for i in range(len(dataset)):\n",
        "\n",
        "    # single sample\n",
        "    batch = dataset[i]\n",
        "    X = batch['features'].unsqueeze(0).to(DEVICE)\n",
        "    R_actual = batch['returns'].cpu().numpy()\n",
        "\n",
        "    # portfolio weights\n",
        "    weights = model(X).squeeze(0).cpu().numpy()\n",
        "\n",
        "    # store weights, returns, dates\n",
        "    predicted_weights.append(weights)\n",
        "    actual_returns.append(R_actual)\n",
        "    dates.append(all_dates[i])\n",
        "\n",
        "    # portfolio return: dot product of weights and actual returns\n",
        "    Rp_t = np.sum(weights * R_actual)\n",
        "    portfolio_returns.append(Rp_t)\n",
        "\n",
        "# to np\n",
        "predicted_weights = np.array(predicted_weights)\n",
        "actual_returns = np.array(actual_returns)\n",
        "portfolio_returns = np.array(portfolio_returns)\n",
        "\n",
        "# compound return\n",
        "compounded_returns = (1 + portfolio_returns).cumprod()\n",
        "\n",
        "cumulative_sharpe_ratios = []\n",
        "for j in range(len(portfolio_returns)):\n",
        "  returns_subset = portfolio_returns[:j+1]\n",
        "\n",
        "  if len(returns_subset) > 1:\n",
        "    mean_return = np.mean(returns_subset)\n",
        "    std_return = np.std(returns_subset, ddof=0)\n",
        "\n",
        "    if std_return != 0:\n",
        "      # sharpe ratio no risk free\n",
        "      sharpe = (mean_return / std_return)\n",
        "    else:\n",
        "      sharpe = 0\n",
        "    cumulative_sharpe_ratios.append(sharpe)\n",
        "  else:\n",
        "    cumulative_sharpe_ratios.append(0)\n",
        "\n",
        "cumulative_sharpe_ratios = np.array(cumulative_sharpe_ratios)\n",
        "\n",
        "# feature cross section\n",
        "cumulative_return_feature_data_for_plot = data.loc[dates].xs('cumulative_return', level=1, axis=1)\n",
        "\n",
        "fig, axes = plt.subplots(3, 1, figsize=(14, 15), sharex=True)\n",
        "\n",
        "# weights vs time\n",
        "axes[0].set_title('Portfolio Weights Over Time (Model Predictions)')\n",
        "axes[0].set_ylabel('Weight')\n",
        "for i, etf in enumerate(ETFS):\n",
        "  axes[0].plot(dates, predicted_weights[:, i], label=etf)\n",
        "axes[0].legend(title='ETFs')\n",
        "axes[0].grid(True)\n",
        "\n",
        "# return vs time\n",
        "axes[1].set_title('Cumulative Return Feature Over Time for Each ETF')\n",
        "axes[1].set_ylabel('Cumulative Return')\n",
        "cumulative_return_feature_data_for_plot.plot(ax=axes[1])\n",
        "axes[1].legend(title='ETFs')\n",
        "axes[1].grid(True)\n",
        "\n",
        "# shapre vs time\n",
        "axes[2].set_title('Cumulative Sharpe Ratio of Model Portfolio Over Time (Annualized)')\n",
        "axes[2].set_ylabel('Sharpe Ratio')\n",
        "axes[2].set_xlabel('Date')\n",
        "axes[2].plot(dates, cumulative_sharpe_ratios)\n",
        "axes[2].grid(True)\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
